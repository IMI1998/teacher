import streamlit as st
import os
import tempfile

from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS

from langchain_groq import ChatGroq

from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.chat_history import InMemoryChatMessageHistory
from langchain_core.runnables import RunnableWithMessageHistory

# ---------------------------------------------------
# Streamlit UI
# ---------------------------------------------------
st.set_page_config(page_title="Ø§Ø³ØªØ§Ø¯ MIT", layout="wide")

st.markdown("""
<style>
    body { direction: rtl; text-align: right; }
    .stChatMessage { direction: rtl; text-align: right; }
    .stMarkdown { direction: rtl; text-align: right; }
    .stMarkdown > div > p { direction: rtl; text-align: right; }
    .stSpinner { direction: rtl; text-align: right; }
    div { direction: rtl; text-align: right; }
    p { direction: rtl; text-align: right; }
    h1, h2, h3, h4, h5, h6 { direction: rtl; text-align: right; }
    li { direction: rtl; text-align: right; }
    code { direction: ltr; text-align: left; unicode-bidi: embed; }  /* Ø¨Ø±Ø§ÛŒ Ú©Ø¯Ù‡Ø§ÛŒ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ LTR Ù†Ú¯Ù‡ Ø¯Ø§Ø±ÛŒÙ… */
</style>
""", unsafe_allow_html=True)

st.title("ğŸ“ Ø§Ø³ØªØ§Ø¯ Ø®ØµÙˆØµÛŒ MIT - Ù†Ø³Ø®Ù‡ Ù¾Ø§ÛŒØ¯Ø§Ø±")

with st.sidebar:
    api_key = st.text_input("Groq API Key", type="password")
    uploaded_file = st.file_uploader("Ú©ØªØ§Ø¨ PDF Ø±Ø§ Ø¢Ù¾Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯", type="pdf")

    if st.button("Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† Ø­Ø§ÙØ¸Ù‡ Ú¯ÙØªÚ¯Ùˆ"):
        st.session_state.histories = {}
        st.rerun()

# ---------------------------------------------------
# PDF â†’ Vectorstore
# ---------------------------------------------------
@st.cache_resource
def process_pdf(file):
    with tempfile.NamedTemporaryFile(delete=False) as tmp:
        tmp.write(file.getvalue())
        temp_path = tmp.name

    loader = PyPDFLoader(temp_path)
    docs = loader.load()

    # Ø®Ø±Ø¯ Ú©Ø±Ø¯Ù† Ù…ØªÙ† PDF
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,
        chunk_overlap=150
    )
    chunks = splitter.split_documents(docs)

    # Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ù…ØªÙ†â€ŒÙ‡Ø§ Ø§Ø² newline
    for doc in chunks:
        doc.page_content = doc.page_content.replace("\n", " ")

    embeddings = HuggingFaceEmbeddings(
        model_name="sentence-transformers/all-MiniLM-L6-v2"
    )

    vectorstore = FAISS.from_documents(chunks, embeddings)
    os.remove(temp_path)
    return vectorstore

# ---------------------------------------------------
# Ø­Ø§ÙØ¸Ù‡ Ú¯ÙØªÚ¯Ùˆ
# ---------------------------------------------------
if "histories" not in st.session_state:
    st.session_state.histories = {}

def get_history(session_id):
    if session_id not in st.session_state.histories:
        st.session_state.histories[session_id] = InMemoryChatMessageHistory()
    return st.session_state.histories[session_id]

# ---------------------------------------------------
# Prompt Template Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ
# ---------------------------------------------------
prompt = ChatPromptTemplate.from_messages([
    ("system",
     """
You are a top-tier MIT professor AND an Iranian Konkur (entrance exam) instructor.
Your mission is TEACHING, not just answering and translating.

You must ALWAYS:
1. Detect and analyze examples inside the retrieved PDF context.
2. If the context contains an example, solve it step-by-step like a Konkur teacher.
3. Extract formulas, definitions, and key points.
4. Warn the student about common misconceptions and traps.
5. Produce 1â€“3 NEW similar practice problems with answers.
6. Use Persian for teaching. Use English only for technical terms.
7. When answering:
   - Ø¨Ø®Ø´ Û±: Ø®Ù„Ø§ØµÙ‡ Ù…ÙÙ‡ÙˆÙ… Ø§ØµÙ„ÛŒ
   - Ø¨Ø®Ø´ Û²: ØªØ­Ù„ÛŒÙ„ Ø®Ø· Ø¨Ù‡ Ø®Ø· Ù…Ø­ØªÙˆØ§ÛŒ PDF Ù…Ø±Ø¨ÙˆØ·Ù‡
   - Ø¨Ø®Ø´ Û³: ØªØ­Ù„ÛŒÙ„ Ú©Ø§Ù…Ù„ Ù…Ø«Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ø¯Ø± PDF
   - Ø¨Ø®Ø´ Û´: Ù…Ø«Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯ Ù…Ø´Ø§Ø¨Ù‡ Ø¨Ø±Ø§ÛŒ ØªÙ…Ø±ÛŒÙ†
   - Ø¨Ø®Ø´ Ûµ: Ù†Ú©Ø§Øª Ú©Ù†Ú©ÙˆØ±ÛŒØŒ Ø¯Ø§Ù…â€ŒÙ‡Ø§ØŒ Ø±ÙˆØ´ Ù…ÛŒØ§Ù†â€ŒØ¨Ø±
   - Ø¨Ø®Ø´ 6: Ø§Ø±Ø§Ø¯Ø¦Ù‡ Ø±ÙˆØ´ Ù‡Ø§ÛŒ ØªØ³Øª Ø²Ù†ÛŒ Ø³Ø±ÛŒØ¹ Ø±ÙˆØ´ Ù‡Ø§ÛŒ Ø±ÙˆØ² Ø¯Ù†ÛŒØ§ Ùˆ Ø³Ø±ÛŒØ¹ Ø§ÛŒÙ† Ø±ÙˆØ´ Ù‡Ø§ Ù…ÛŒØªÙˆØ§Ù†Ø¯ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ø®ÙˆØ¯Øª ÛŒØ§ Ø¯ÛŒÚ¯Ø±Ø§Ù† Ø¨Ø§Ø´Ø¯
8.In-depth and conceptual teaching is very important. Even the smallest concepts should not be left out.
9.Within the lesson, there may be exercises and problems that you must solve for me and explain fully so that I can learn completely.
10.Imagine that I know nothing and I expect you to teach me everything from scratch, completely and comprehensively, by providing test and conceptual tips. Nothing should be left out.
Your teaching style must be:
- precise
- structured
- exam-oriented
- clear and deep

CONTEXT FROM BOOK:
{context}
"""),
    MessagesPlaceholder(variable_name="chat_history"),
    ("user",
     """
Ù¾Ø±Ø³Ø´ Ø¯Ø§Ù†Ø´Ø¬Ùˆ:
{question}
""")
])

# ---------------------------------------------------
# Ø³Ø§Ø®Øª chain RAG + LLM
# ---------------------------------------------------
def build_chain(vectorstore, api_key):
    retriever = vectorstore.as_retriever(search_kwargs={"k": 4})

    llm = ChatGroq(
        groq_api_key=api_key,
        model_name="openai/gpt-oss-120b",
        temperature=0.3
    )

    chain = (
        {
            "context": lambda x: "\n\n".join(
                 doc.page_content for doc in retriever.invoke(x["question"])
                ),
            "question": lambda x: x["question"],
            "chat_history": lambda x: x["chat_history"]
        }
        | prompt
        | llm
    )

    return RunnableWithMessageHistory(
        chain,
        get_history,
        input_messages_key="question",
        history_messages_key="chat_history"
    )

# ---------------------------------------------------
# Ø§Ø¬Ø±Ø§ÛŒ Ú†Øª
# ---------------------------------------------------
if uploaded_file and api_key:

    vectorstore = process_pdf(uploaded_file)
    chat = build_chain(vectorstore, api_key)

    st.success("Ú©ØªØ§Ø¨ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯. Ø³ÙˆØ§Ù„ Ø®ÙˆØ¯ Ø±Ø§ Ø¨Ù¾Ø±Ø³ÛŒØ¯.")

    session_id = "student"
    history = get_history(session_id)

    # Ù†Ù…Ø§ÛŒØ´ ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ú†Øª
    for msg in history.messages:
        with st.chat_message("assistant" if msg.type == "ai" else "user"):
            st.markdown(msg.content, unsafe_allow_html=True)  # Ø§Ø² markdown Ø¨Ø±Ø§ÛŒ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø¨Ù‡ØªØ± RTL Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†

    # Ø¯Ø±ÛŒØ§ÙØª Ø³ÙˆØ§Ù„ Ø¬Ø¯ÛŒØ¯
    if question := st.chat_input("Ø³ÙˆØ§Ù„ Ø®ÙˆØ¯ Ø±Ø§ Ø¨Ù¾Ø±Ø³ÛŒØ¯..."):
        with st.chat_message("user"):
            st.write(question)

        with st.chat_message("assistant"):
            with st.spinner("Ø¯Ø± Ø­Ø§Ù„ ÙÚ©Ø± Ú©Ø±Ø¯Ù†..."):
                result = chat.invoke(
                    {"question": question},
                    config={"configurable": {"session_id": session_id}}
                )
                st.markdown(result.content, unsafe_allow_html=True)  # Ø§Ø² markdown Ø¨Ø±Ø§ÛŒ RTL Ø¨Ù‡ØªØ±

else:

    st.info("Ù„Ø·ÙØ§Ù‹ API Key Ùˆ PDF Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯.")

